{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports done\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing  import MinMaxScaler, MaxAbsScaler\n",
    "\n",
    "# model imports\n",
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Support Vector Machines\n",
    "from sklearn.svm import SVC\n",
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# K-Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Gradient Boost\n",
    "# Ada Boost\n",
    "from sklearn.tree import DecisionTreeClassifier # requirement for ada gradient boost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "print('imports done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('./train_processed.csv')\n",
    "test_data = pd.read_csv('./test_processed.csv')\n",
    "print('data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data splitted\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "train_dataset, val_dataset = train_test_split(train_data, test_size=0.3, random_state=42)\n",
    "print('data splitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train labels shape:  (623,)\n",
      "val labels shape:  (268,)\n",
      "labels extracted\n"
     ]
    }
   ],
   "source": [
    "# extract labels\n",
    "train_labels = train_dataset.pop('Survived')\n",
    "val_labels = val_dataset.pop('Survived')\n",
    "\n",
    "print('train labels shape: ', str(train_labels.shape))\n",
    "print('val labels shape: ', str(val_labels.shape))\n",
    "\n",
    "print('labels extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passengerId copied and removed\n"
     ]
    }
   ],
   "source": [
    "# Extract passengerId\n",
    "\n",
    "passengerId = test_data['PassengerId']\n",
    "train_dataset = train_dataset.drop(columns=['PassengerId'])\n",
    "val_dataset = val_dataset.drop(columns=['PassengerId'])\n",
    "test_data = test_data.drop(columns=['PassengerId'])\n",
    "print('passengerId copied and removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using MinMax scaler we noticed that it was complaining because train_data_encoded is sparse, this means that most of its values are zero. so, we're going to use MaxAbsScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (623, 12)\n",
      "val shape:  (268, 12)\n",
      "test shape:  (418, 12)\n",
      "max value train scaled:  1.0\n",
      "max value val scaled:  1.0666666666666667\n",
      "max value test:  1.5\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_dataset)\n",
    "val_data_scaled = scaler.transform(val_dataset)\n",
    "test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "print('train shape: ', train_data_scaled.shape)\n",
    "print('val shape: ', val_data_scaled.shape)\n",
    "print('test shape: ', test_data_scaled.shape)\n",
    "\n",
    "print('max value train scaled: ', np.max(train_data_scaled))\n",
    "print('max value val scaled: ', np.max(val_data_scaled))\n",
    "print('max value test: ', np.max(test_data_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models set\n"
     ]
    }
   ],
   "source": [
    "# logistic regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(train_data_scaled, train_labels)\n",
    "\n",
    "# random forest model\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_model.fit(train_data_scaled, train_labels)\n",
    "\n",
    "# support vector classifier model\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_model.fit(train_data_scaled, train_labels)\n",
    "\n",
    "# naive bayes multinomial classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(train_data_scaled, train_labels)\n",
    "\n",
    "# k-nearest neighbors classifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(train_data_scaled, train_labels)\n",
    "\n",
    "# Adaboost classifier\n",
    "adaboost_base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "adaboost_model = AdaBoostClassifier(adaboost_base_classifier, n_estimators=50, random_state=42)\n",
    "adaboost_model.fit(train_data_scaled, train_labels)\n",
    "\n",
    "print('models set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to show metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics(train_pred):\n",
    "    accuracy = accuracy_score(val_labels, train_pred)\n",
    "    confusion = confusion_matrix(val_labels, train_pred)\n",
    "    report = classification_report(val_labels, train_pred)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Confusion Matrix:\\n\", confusion)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict with different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7947761194029851\n",
      "Confusion Matrix:\n",
      " [[133  24]\n",
      " [ 31  80]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       157\n",
      "           1       0.77      0.72      0.74       111\n",
      "\n",
      "    accuracy                           0.79       268\n",
      "   macro avg       0.79      0.78      0.79       268\n",
      "weighted avg       0.79      0.79      0.79       268\n",
      "\n",
      "train preds made for regression model\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "val_preds_regression_model = logistic_regression_model.predict(val_data_scaled)\n",
    "regression_model_accuracy = model_metrics(val_preds_regression_model)\n",
    "\n",
    "logistic_regresion_preds = logistic_regression_model.predict(test_data_scaled)\n",
    "print('train preds made for regression model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8134328358208955\n",
      "Confusion Matrix:\n",
      " [[136  21]\n",
      " [ 29  82]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       157\n",
      "           1       0.80      0.74      0.77       111\n",
      "\n",
      "    accuracy                           0.81       268\n",
      "   macro avg       0.81      0.80      0.81       268\n",
      "weighted avg       0.81      0.81      0.81       268\n",
      "\n",
      "train preds made for random forest model\n"
     ]
    }
   ],
   "source": [
    "# Random forest model\n",
    "val_preds_random_forest_model = random_forest_model.predict(val_data_scaled)\n",
    "random_forest_model_accuracy = model_metrics(val_preds_random_forest_model)\n",
    "\n",
    "random_forest_model_preds = random_forest_model.predict(test_data_scaled)\n",
    "print('train preds made for random forest model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7910447761194029\n",
      "Confusion Matrix:\n",
      " [[134  23]\n",
      " [ 33  78]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83       157\n",
      "           1       0.77      0.70      0.74       111\n",
      "\n",
      "    accuracy                           0.79       268\n",
      "   macro avg       0.79      0.78      0.78       268\n",
      "weighted avg       0.79      0.79      0.79       268\n",
      "\n",
      "train preds made for svm model\n"
     ]
    }
   ],
   "source": [
    "# Support vector machine\n",
    "val_preds_svm_model = svm_model.predict(val_data_scaled)\n",
    "svm_model_accuracy = model_metrics(val_preds_svm_model)\n",
    "\n",
    "svm_model_preds = svm_model.predict(test_data_scaled)\n",
    "print('train preds made for svm model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7910447761194029\n",
      "Confusion Matrix:\n",
      " [[134  23]\n",
      " [ 33  78]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83       157\n",
      "           1       0.77      0.70      0.74       111\n",
      "\n",
      "    accuracy                           0.79       268\n",
      "   macro avg       0.79      0.78      0.78       268\n",
      "weighted avg       0.79      0.79      0.79       268\n",
      "\n",
      "train preds made for nb model\n"
     ]
    }
   ],
   "source": [
    "# Naive bayes\n",
    "val_preds_nb_model = nb_model.predict(val_data_scaled)\n",
    "nb_model_accuracy = model_metrics(val_preds_nb_model)\n",
    "\n",
    "nb_model_preds = nb_model.predict(test_data_scaled)\n",
    "print('train preds made for nb model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8022388059701493\n",
      "Confusion Matrix:\n",
      " [[139  18]\n",
      " [ 35  76]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84       157\n",
      "           1       0.81      0.68      0.74       111\n",
      "\n",
      "    accuracy                           0.80       268\n",
      "   macro avg       0.80      0.79      0.79       268\n",
      "weighted avg       0.80      0.80      0.80       268\n",
      "\n",
      "train preds for knn model\n"
     ]
    }
   ],
   "source": [
    "# K - nearest neighbors\n",
    "val_preds_knn_model = knn_model.predict(val_data_scaled)\n",
    "knn_model_accuracy = model_metrics(val_preds_knn_model)\n",
    "\n",
    "knn_model_preds = knn_model.predict(test_data_scaled)\n",
    "print('train preds for knn model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7985074626865671\n",
      "Confusion Matrix:\n",
      " [[135  22]\n",
      " [ 32  79]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83       157\n",
      "           1       0.78      0.71      0.75       111\n",
      "\n",
      "    accuracy                           0.80       268\n",
      "   macro avg       0.80      0.79      0.79       268\n",
      "weighted avg       0.80      0.80      0.80       268\n",
      "\n",
      "train preds for adaboost model\n"
     ]
    }
   ],
   "source": [
    "# adaboost\n",
    "val_preds_adaboost_model = adaboost_model.predict(val_data_scaled)\n",
    "adaboost_model_accuracy = model_metrics(val_preds_adaboost_model)\n",
    "\n",
    "adaboost_model_preds = adaboost_model.predict(test_data_scaled)\n",
    "print('train preds for adaboost model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission set\n"
     ]
    }
   ],
   "source": [
    "# generate data frame for submision\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": passengerId,\n",
    "    \"Survived\": nb_model_preds\n",
    "})\n",
    "\n",
    "print('submission set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission file generated\n"
     ]
    }
   ],
   "source": [
    "# write the file to submission\n",
    "submission.to_csv('./submissions/titanic_dissaster_nb_model_preds_2.csv', index=False, header=True)\n",
    "print('submission file generated')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanicCompetition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
