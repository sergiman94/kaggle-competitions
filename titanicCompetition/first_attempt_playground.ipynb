{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-07T19:11:43.277132Z","iopub.status.busy":"2023-11-07T19:11:43.276704Z","iopub.status.idle":"2023-11-07T19:11:43.286925Z","shell.execute_reply":"2023-11-07T19:11:43.286128Z","shell.execute_reply.started":"2023-11-07T19:11:43.277085Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-21 12:13:40.870988: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["imports finished\n"]}],"source":["# usual imports \n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dense, Dropout\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# model imports\n","# logistic regression\n","from sklearn.linear_model import LogisticRegression\n","# Random Forest\n","from sklearn.ensemble import RandomForestClassifier\n","# Support Vector Machines\n","from sklearn.svm import SVC\n","# Multinomial Naive Bayes\n","from sklearn.naive_bayes import MultinomialNB\n","# K-Neighbors\n","from sklearn.neighbors import KNeighborsClassifier\n","# Gradient Boost\n","# Ada Boost\n","from sklearn.tree import DecisionTreeClassifier # requirement for ada gradient boost\n","from sklearn.ensemble import AdaBoostClassifier \n","print('imports finished')"]},{"cell_type":"markdown","metadata":{},"source":["## Load Data"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:11:45.511757Z","iopub.status.busy":"2023-11-07T19:11:45.511341Z","iopub.status.idle":"2023-11-07T19:11:45.530034Z","shell.execute_reply":"2023-11-07T19:11:45.528650Z","shell.execute_reply.started":"2023-11-07T19:11:45.511723Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["data loaded\n"]}],"source":["train_dataset = pd.read_csv('./train.csv')\n","test_data = pd.read_csv('./test.csv')\n","print('data loaded')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:11:47.601339Z","iopub.status.busy":"2023-11-07T19:11:47.600678Z","iopub.status.idle":"2023-11-07T19:11:47.610143Z","shell.execute_reply":"2023-11-07T19:11:47.608765Z","shell.execute_reply.started":"2023-11-07T19:11:47.601293Z"},"trusted":true},"outputs":[],"source":["# split data\n","# train_dataset, val_dataset = train_test_split(train_data, test_size=0.3, random_state=42)\n","# print('data splitted')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:11:49.665503Z","iopub.status.busy":"2023-11-07T19:11:49.665081Z","iopub.status.idle":"2023-11-07T19:11:49.673748Z","shell.execute_reply":"2023-11-07T19:11:49.672626Z","shell.execute_reply.started":"2023-11-07T19:11:49.665471Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train labels shape:  (891,)\n","labels extracted\n"]}],"source":["# extract labels\n","train_labels = train_dataset.pop('Survived')\n","# val_labels = val_dataset.pop('Survived')\n","\n","print('train labels shape: ', str(train_labels.shape))\n","# print('val labels shape: ', str(val_labels.shape))\n","\n","print('labels extracted')"]},{"cell_type":"markdown","metadata":{},"source":["## EDA - Data Exploration"]},{"cell_type":"markdown","metadata":{},"source":["### Shapes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:11:51.786785Z","iopub.status.busy":"2023-11-07T19:11:51.786390Z","iopub.status.idle":"2023-11-07T19:11:51.794730Z","shell.execute_reply":"2023-11-07T19:11:51.793413Z","shell.execute_reply.started":"2023-11-07T19:11:51.786755Z"},"trusted":true},"outputs":[],"source":["print('train shape: ' + str(train_dataset.shape))\n","# print('val shape: ' + str(val_dataset.shape))\n","print('test data shape: '+ str(test_data.shape))"]},{"cell_type":"markdown","metadata":{},"source":["### Traininig data info"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:11:53.990635Z","iopub.status.busy":"2023-11-07T19:11:53.990226Z","iopub.status.idle":"2023-11-07T19:11:54.007608Z","shell.execute_reply":"2023-11-07T19:11:54.006349Z","shell.execute_reply.started":"2023-11-07T19:11:53.990599Z"},"trusted":true},"outputs":[],"source":["# train_dataset.info()"]},{"cell_type":"markdown","metadata":{},"source":["### Check categorical columns"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:11:55.565023Z","iopub.status.busy":"2023-11-07T19:11:55.564493Z","iopub.status.idle":"2023-11-07T19:11:55.573330Z","shell.execute_reply":"2023-11-07T19:11:55.572056Z","shell.execute_reply.started":"2023-11-07T19:11:55.564972Z"},"trusted":true},"outputs":[],"source":["# cat_cols = train_dataset.select_dtypes(include=('object')).columns.to_list()\n","# print(cat_cols)\n","# print('number of cat_cols: ' + str(len(cat_cols)))"]},{"cell_type":"markdown","metadata":{},"source":["## Data Cleaning"]},{"cell_type":"markdown","metadata":{},"source":["### Removing Columns - from EDA "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:11:59.471013Z","iopub.status.busy":"2023-11-07T19:11:59.470564Z","iopub.status.idle":"2023-11-07T19:11:59.481939Z","shell.execute_reply":"2023-11-07T19:11:59.481025Z","shell.execute_reply.started":"2023-11-07T19:11:59.470977Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Columns removed\n"]}],"source":["# removing passengerId, cabin, column \n","passengerId = test_data['PassengerId']\n","\n","# dropping unnecesary columns\n","train_dataset = train_dataset.drop(columns=['Cabin', 'PassengerId'])\n","# val_dataset = val_dataset.drop(columns=['Cabin', 'PassengerId'])\n","test_data = test_data.drop(columns=['Cabin', 'PassengerId'])\n","print('Columns removed')"]},{"cell_type":"markdown","metadata":{},"source":["### Handle Missing Values"]},{"cell_type":"markdown","metadata":{},"source":["#### Training dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:02.755436Z","iopub.status.busy":"2023-11-07T19:12:02.754968Z","iopub.status.idle":"2023-11-07T19:12:02.767853Z","shell.execute_reply":"2023-11-07T19:12:02.766528Z","shell.execute_reply.started":"2023-11-07T19:12:02.755398Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["training dataset missing values handled\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 891 entries, 0 to 890\n","Data columns (total 9 columns):\n"," #   Column    Non-Null Count  Dtype  \n","---  ------    --------------  -----  \n"," 0   Pclass    891 non-null    int64  \n"," 1   Name      891 non-null    object \n"," 2   Sex       891 non-null    object \n"," 3   Age       891 non-null    float64\n"," 4   SibSp     891 non-null    int64  \n"," 5   Parch     891 non-null    int64  \n"," 6   Ticket    891 non-null    object \n"," 7   Fare      891 non-null    float64\n"," 8   Embarked  891 non-null    object \n","dtypes: float64(2), int64(3), object(4)\n","memory usage: 62.8+ KB\n"]}],"source":["# handle Age column missing values\n","train_ages = train_dataset['Age']\n","train_non_nan_ages = train_ages[~np.isnan(train_ages)]\n","train_ages_mean = train_non_nan_ages.mean()\n","train_dataset['Age'] = train_dataset['Age'].fillna(train_ages_mean)\n","# handle Embarked missing values\n","train_embarked = train_dataset['Embarked']\n","train_embarked_mode = train_embarked.mode()\n","train_dataset['Embarked'].replace(' ', np.nan, inplace=True) # Replacing non-visible missing values with NaN\n","train_dataset['Embarked'] = train_dataset['Embarked'].fillna('S')\n","print('training dataset missing values handled')\n","train_dataset.info()"]},{"cell_type":"markdown","metadata":{},"source":["#### Val dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:08.179402Z","iopub.status.busy":"2023-11-07T19:12:08.178705Z","iopub.status.idle":"2023-11-07T19:12:08.202494Z","shell.execute_reply":"2023-11-07T19:12:08.201193Z","shell.execute_reply.started":"2023-11-07T19:12:08.179353Z"},"trusted":true},"outputs":[],"source":["# # handle Age column missing values\n","# val_ages = val_dataset['Age']\n","# val_non_nan_ages = val_ages[~np.isnan(val_ages)]\n","# val_ages_mean = val_non_nan_ages.mean() # handling missing values with the mean of the ages\n","# val_dataset['Age'] = val_dataset['Age'].fillna(val_ages_mean)\n","# # handle Embarked\n","# val_embarked = val_dataset['Embarked']\n","# val_embarked_mode = val_dataset.mode()\n","# val_dataset['Embarked'].replace(' ', np.nan, inplace=True) # Replacing non-visible missing values with NaN\n","# val_dataset['Embarked'] = val_dataset['Embarked'].fillna('S')\n","# print('val dataset missing values handled')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:10.537274Z","iopub.status.busy":"2023-11-07T19:12:10.536851Z","iopub.status.idle":"2023-11-07T19:12:10.551648Z","shell.execute_reply":"2023-11-07T19:12:10.550348Z","shell.execute_reply.started":"2023-11-07T19:12:10.537242Z"},"trusted":true},"outputs":[],"source":["# val_dataset.info()"]},{"cell_type":"markdown","metadata":{},"source":["#### Test data"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:12.476842Z","iopub.status.busy":"2023-11-07T19:12:12.476426Z","iopub.status.idle":"2023-11-07T19:12:12.489605Z","shell.execute_reply":"2023-11-07T19:12:12.488174Z","shell.execute_reply.started":"2023-11-07T19:12:12.476810Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["test data missing values handled\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 418 entries, 0 to 417\n","Data columns (total 9 columns):\n"," #   Column    Non-Null Count  Dtype  \n","---  ------    --------------  -----  \n"," 0   Pclass    418 non-null    int64  \n"," 1   Name      418 non-null    object \n"," 2   Sex       418 non-null    object \n"," 3   Age       418 non-null    float64\n"," 4   SibSp     418 non-null    int64  \n"," 5   Parch     418 non-null    int64  \n"," 6   Ticket    418 non-null    object \n"," 7   Fare      418 non-null    float64\n"," 8   Embarked  418 non-null    object \n","dtypes: float64(2), int64(3), object(4)\n","memory usage: 29.5+ KB\n"]}],"source":["# handle Age column missing values\n","test_ages = test_data['Age']\n","test_non_nan_ages = test_ages[~np.isnan(test_ages)]\n","test_ages_mean = test_non_nan_ages.mean()\n","test_data['Age'] = test_data['Age'].fillna(test_ages_mean)\n","# handle Embarked\n","test_data['Embarked'].replace(' ', np.nan, inplace=True) # Replacing non-visible missing values with NaN\n","test_data['Embarked'] = test_data['Embarked'].fillna('S') # imputing 'S' from mode \n","# handle Fare\n","test_data['Fare'].replace(' ', np.nan, inplace=True)\n","test_data['Fare'] = test_data['Fare'].fillna(7.75) # 7.75 from mode\n","print('test data missing values handled')\n","test_data.info()"]},{"cell_type":"markdown","metadata":{},"source":["### Handle Categorical values (encoding)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:16.631689Z","iopub.status.busy":"2023-11-07T19:12:16.631271Z","iopub.status.idle":"2023-11-07T19:12:16.711161Z","shell.execute_reply":"2023-11-07T19:12:16.709907Z","shell.execute_reply.started":"2023-11-07T19:12:16.631654Z"},"trusted":true},"outputs":[],"source":["# init the encoder\n","encoder = OneHotEncoder(handle_unknown='ignore')\n","# encoder = TargetEncoder()\n","\n","# get categorical columns\n","cat_cols = [cname for cname in train_dataset.columns if \n","           train_dataset[cname].dtype == \"object\"]\n","\n","print('processing the following cat cols: ' + str(cat_cols))\n","\n","# fit the encoder in the training data and then use it on the other datasets\n","train_data_encoded = encoder.fit_transform(train_dataset[cat_cols])\n","# val_data_encoded = encoder.transform(val_dataset[cat_cols])\n","test_data_encoded = encoder.transform(test_data[cat_cols])\n","\n","# convert encoded datasets to pandas dataframes \n","train_data_encoded_df = pd.DataFrame(train_data_encoded.toarray(), columns=encoder.get_feature_names_out(cat_cols))\n","# val_data_encoded_df = pd.DataFrame(val_data_encoded.toarray(), columns=encoder.get_feature_names_out(cat_cols))\n","test_data_encoded_df = pd.DataFrame(test_data_encoded.toarray(), columns=encoder.get_feature_names_out(cat_cols))\n","\n","# drop cat cols from original dataset\n","train_dataset = train_dataset.drop(columns=cat_cols, axis=1)\n","# val_dataset = val_dataset.drop(columns=cat_cols, axis=1)\n","test_data = test_data.drop(columns=cat_cols, axis=1)\n","\n","# Concatenate with the rest of the features (here we do .reset_index(drop=True) to reset the prevs persisted indexes)\n","train_dataset_encoded = pd.concat([train_dataset.reset_index(drop=True), train_data_encoded_df], axis=1)\n","# val_dataset_encoded = pd.concat([val_dataset.reset_index(drop=True), val_data_encoded_df], axis=1)\n","test_dataset_encoded = pd.concat([test_data.reset_index(drop=True), test_data_encoded_df], axis=1)\n","\n","print(train_dataset_encoded.shape)\n","# print(val_dataset_encoded.shape)\n","print(test_dataset_encoded.shape)\n","\n","print('categorical data handled')"]},{"cell_type":"markdown","metadata":{},"source":["### Normalization"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:21.452902Z","iopub.status.busy":"2023-11-07T19:12:21.452403Z","iopub.status.idle":"2023-11-07T19:12:21.552013Z","shell.execute_reply":"2023-11-07T19:12:21.550765Z","shell.execute_reply.started":"2023-11-07T19:12:21.452859Z"},"trusted":true},"outputs":[],"source":["# initialized the scaler \n","scaler = MinMaxScaler()\n","\n","# normalize train data\n","train_data_scaled = scaler.fit_transform(train_dataset_encoded)\n","# val_data_scaled = scaler.transform(val_dataset_encoded)\n","test_data_scaled = scaler.transform(test_dataset_encoded)\n","\n","print(train_data_scaled.shape)\n","# print(val_data_scaled.shape)\n","print(test_data_scaled.shape)\n","\n","print('data normalized')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:24.844679Z","iopub.status.busy":"2023-11-07T19:12:24.844301Z","iopub.status.idle":"2023-11-07T19:12:24.852232Z","shell.execute_reply":"2023-11-07T19:12:24.851006Z","shell.execute_reply.started":"2023-11-07T19:12:24.844650Z"},"trusted":true},"outputs":[],"source":["# Verify that data has been normalized correctly\n","print(np.max(train_data_scaled))\n","print(np.min(train_data_scaled))"]},{"cell_type":"markdown","metadata":{},"source":["## Build the models"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# put the train labels again before splitting\n","train_labels_df = train_labels.to_frame(name='Survived')\n","train_dataset = pd.concat([train_dataset, train_labels_df], axis=1)\n","train_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# split data\n","train_data, val_data = train_test_split(train_dataset, test_size=0.3, random_state=42)\n","# print('data splitted')"]},{"cell_type":"markdown","metadata":{},"source":["### Models Implementation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:29.952167Z","iopub.status.busy":"2023-11-07T19:12:29.951711Z","iopub.status.idle":"2023-11-07T19:12:31.405351Z","shell.execute_reply":"2023-11-07T19:12:31.404142Z","shell.execute_reply.started":"2023-11-07T19:12:29.952126Z"},"trusted":true},"outputs":[],"source":["# logistic regression model\n","logistic_regression_model = LogisticRegression()\n","logistic_regression_model.fit(train_data_scaled, train_labels)\n","\n","# random forest model\n","random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","random_forest_model.fit(train_data_scaled, train_labels)\n","\n","# support vector classifier model\n","svm_model = SVC(kernel=\"linear\")\n","svm_model.fit(train_data_scaled, train_labels)\n","\n","# naive bayes multinomial classifier\n","nb_model = MultinomialNB()\n","nb_model.fit(train_data_scaled, train_labels)\n","\n","# k-nearest neighbors classifier\n","knn_model = KNeighborsClassifier(n_neighbors=5)\n","knn_model.fit(train_data_scaled, train_labels)\n","\n","# Adaboost classifier\n","adaboost_base_classifier = DecisionTreeClassifier(max_depth=1)\n","adaboost_model = AdaBoostClassifier(adaboost_base_classifier, n_estimators=50, random_state=42)\n","adaboost_model.fit(train_data_scaled, train_labels)\n","\n","print('models set')"]},{"cell_type":"markdown","metadata":{},"source":["## Make Predictions"]},{"cell_type":"markdown","metadata":{},"source":["### Generate predictions for Logistic Regression Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:35.491390Z","iopub.status.busy":"2023-11-07T19:12:35.490752Z","iopub.status.idle":"2023-11-07T19:12:35.499193Z","shell.execute_reply":"2023-11-07T19:12:35.497646Z","shell.execute_reply.started":"2023-11-07T19:12:35.491351Z"},"trusted":true},"outputs":[],"source":["def model_metrics(train_pred):\n","    accuracy = accuracy_score(val_labels, train_pred)\n","    confusion = confusion_matrix(val_labels, train_pred)\n","    report = classification_report(val_labels, train_pred)\n","\n","    print(\"Accuracy:\", accuracy)\n","    print(\"Confusion Matrix:\\n\", confusion)\n","    print(\"Classification Report:\\n\", report)\n","    \n","    return accuracy"]},{"cell_type":"markdown","metadata":{},"source":["#### train predictions "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:04:56.541688Z","iopub.status.busy":"2023-11-07T19:04:56.541246Z","iopub.status.idle":"2023-11-07T19:04:56.579919Z","shell.execute_reply":"2023-11-07T19:04:56.578172Z","shell.execute_reply.started":"2023-11-07T19:04:56.541652Z"},"trusted":true},"outputs":[],"source":["val_preds_regression_model = logistic_regression_model.predict(val_data_scaled)\n","regression_model_accuracy = model_metrics(val_preds_regression_model)\n","print('train preds made for regression model')\n","\n","val_preds_random_forest_model = random_forest_model.predict(val_data_scaled)\n","random_forest_model_accuracy = model_metrics(val_preds_random_forest_model)\n","print('train preds made for random forest model')\n","\n","val_preds_svm_model = svm_model.predict(val_data_scaled)\n","svm_model_accuracy = model_metrics(val_preds_svm_model)\n","print('train preds made for svm model')\n","\n","val_preds_nb_model = nb_model.predict(val_data_scaled)\n","nb_model_accuracy = model_metrics(val_preds_nb_model)\n","print('train preds made for nb model')\n","\n","val_preds_knn_model = knn_model.predict(val_data_scaled)\n","knn_model_accuracy = model_metrics(val_preds_knn_model)\n","print('train preds for knn model')\n","\n","val_preds_adaboost_model = adaboost_model.predict(val_data_scaled)\n","adaboost_model_accuracy = model_metrics(val_preds_adaboost_model)\n","print('train preds for adaboost model')"]},{"cell_type":"markdown","metadata":{},"source":["### Submission"]},{"cell_type":"markdown","metadata":{},"source":["#### Real predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:45.797954Z","iopub.status.busy":"2023-11-07T19:12:45.797529Z","iopub.status.idle":"2023-11-07T19:12:45.851769Z","shell.execute_reply":"2023-11-07T19:12:45.850538Z","shell.execute_reply.started":"2023-11-07T19:12:45.797919Z"},"trusted":true},"outputs":[],"source":["preds = nb_model.predict(test_data_scaled)\n","print('train preds made')"]},{"cell_type":"markdown","metadata":{},"source":["#### Generate submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:48.223300Z","iopub.status.busy":"2023-11-07T19:12:48.222833Z","iopub.status.idle":"2023-11-07T19:12:48.230897Z","shell.execute_reply":"2023-11-07T19:12:48.229616Z","shell.execute_reply.started":"2023-11-07T19:12:48.223265Z"},"trusted":true},"outputs":[],"source":["# generate data frame for submision\n","submission = pd.DataFrame({\n","    \"PassengerId\": passengerId,\n","    \"Survived\": preds\n","})\n","\n","print('submission set')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:50.704347Z","iopub.status.busy":"2023-11-07T19:12:50.703923Z","iopub.status.idle":"2023-11-07T19:12:50.716614Z","shell.execute_reply":"2023-11-07T19:12:50.715508Z","shell.execute_reply.started":"2023-11-07T19:12:50.704312Z"},"trusted":true},"outputs":[],"source":["submission.head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:53.585923Z","iopub.status.busy":"2023-11-07T19:12:53.585522Z","iopub.status.idle":"2023-11-07T19:12:53.595566Z","shell.execute_reply":"2023-11-07T19:12:53.594069Z","shell.execute_reply.started":"2023-11-07T19:12:53.585892Z"},"trusted":true},"outputs":[],"source":["# write the file to submission\n","submission.to_csv('./submissions/titanic_dissaster_submission_nb_first_attempt.csv', index=False, header=True)\n","print('submission file generated')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":4}
