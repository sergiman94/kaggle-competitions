{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-07T19:11:43.277132Z","iopub.status.busy":"2023-11-07T19:11:43.276704Z","iopub.status.idle":"2023-11-07T19:11:43.286925Z","shell.execute_reply":"2023-11-07T19:11:43.286128Z","shell.execute_reply.started":"2023-11-07T19:11:43.277085Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["imports finished\n"]}],"source":["# usual imports \n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dense, Dropout\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# model imports\n","# logistic regression\n","from sklearn.linear_model import LogisticRegression\n","# Random Forest\n","from sklearn.ensemble import RandomForestClassifier\n","# Support Vector Machines\n","from sklearn.svm import SVC\n","# Multinomial Naive Bayes\n","from sklearn.naive_bayes import MultinomialNB\n","# K-Neighbors\n","from sklearn.neighbors import KNeighborsClassifier\n","# Gradient Boost\n","# Ada Boost\n","from sklearn.tree import DecisionTreeClassifier # requirement for ada gradient boost\n","from sklearn.ensemble import AdaBoostClassifier \n","print('imports finished')"]},{"cell_type":"markdown","metadata":{},"source":["## Load Data"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:11:45.511757Z","iopub.status.busy":"2023-11-07T19:11:45.511341Z","iopub.status.idle":"2023-11-07T19:11:45.530034Z","shell.execute_reply":"2023-11-07T19:11:45.528650Z","shell.execute_reply.started":"2023-11-07T19:11:45.511723Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["data loaded\n"]}],"source":["train_data = pd.read_csv('./train.csv')\n","test_data = pd.read_csv('./test.csv')\n","\n","print('data loaded')"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:11:47.601339Z","iopub.status.busy":"2023-11-07T19:11:47.600678Z","iopub.status.idle":"2023-11-07T19:11:47.610143Z","shell.execute_reply":"2023-11-07T19:11:47.608765Z","shell.execute_reply.started":"2023-11-07T19:11:47.601293Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["data splitted\n"]}],"source":["# split data\n","train_dataset, val_dataset = train_test_split(train_data, test_size=0.3, random_state=42)\n","print('data splitted')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:11:49.665503Z","iopub.status.busy":"2023-11-07T19:11:49.665081Z","iopub.status.idle":"2023-11-07T19:11:49.673748Z","shell.execute_reply":"2023-11-07T19:11:49.672626Z","shell.execute_reply.started":"2023-11-07T19:11:49.665471Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train labels shape:  (623,)\n","val labels shape:  (268,)\n","labels extracted\n"]}],"source":["# extract labels\n","train_labels = train_dataset.pop('Survived')\n","val_labels = val_dataset.pop('Survived')\n","\n","print('train labels shape: ', str(train_labels.shape))\n","print('val labels shape: ', str(val_labels.shape))\n","\n","print('labels extracted')"]},{"cell_type":"markdown","metadata":{},"source":["## EDA - Data Exploration"]},{"cell_type":"markdown","metadata":{},"source":["### Shapes"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:11:51.786785Z","iopub.status.busy":"2023-11-07T19:11:51.786390Z","iopub.status.idle":"2023-11-07T19:11:51.794730Z","shell.execute_reply":"2023-11-07T19:11:51.793413Z","shell.execute_reply.started":"2023-11-07T19:11:51.786755Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train shape: (623, 11)\n","val shape: (268, 11)\n","test data shape: (418, 11)\n"]}],"source":["print('train shape: ' + str(train_dataset.shape))\n","print('val shape: ' + str(val_dataset.shape))\n","print('test data shape: '+ str(test_data.shape))"]},{"cell_type":"markdown","metadata":{},"source":["### Traininig data info"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:11:53.990635Z","iopub.status.busy":"2023-11-07T19:11:53.990226Z","iopub.status.idle":"2023-11-07T19:11:54.007608Z","shell.execute_reply":"2023-11-07T19:11:54.006349Z","shell.execute_reply.started":"2023-11-07T19:11:53.990599Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 623 entries, 445 to 102\n","Data columns (total 11 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   PassengerId  623 non-null    int64  \n"," 1   Pclass       623 non-null    int64  \n"," 2   Name         623 non-null    object \n"," 3   Sex          623 non-null    object \n"," 4   Age          499 non-null    float64\n"," 5   SibSp        623 non-null    int64  \n"," 6   Parch        623 non-null    int64  \n"," 7   Ticket       623 non-null    object \n"," 8   Fare         623 non-null    float64\n"," 9   Cabin        139 non-null    object \n"," 10  Embarked     622 non-null    object \n","dtypes: float64(2), int64(4), object(5)\n","memory usage: 58.4+ KB\n"]}],"source":["train_dataset.info()"]},{"cell_type":"markdown","metadata":{},"source":["### Check categorical columns"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:11:55.565023Z","iopub.status.busy":"2023-11-07T19:11:55.564493Z","iopub.status.idle":"2023-11-07T19:11:55.573330Z","shell.execute_reply":"2023-11-07T19:11:55.572056Z","shell.execute_reply.started":"2023-11-07T19:11:55.564972Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n","number of cat_cols: 5\n"]}],"source":["cat_cols = train_dataset.select_dtypes(include=('object')).columns.to_list()\n","print(cat_cols)\n","print('number of cat_cols: ' + str(len(cat_cols)))"]},{"cell_type":"markdown","metadata":{},"source":["## Data Preprocessing"]},{"cell_type":"markdown","metadata":{},"source":["### Removing Columns - from EDA "]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:11:59.471013Z","iopub.status.busy":"2023-11-07T19:11:59.470564Z","iopub.status.idle":"2023-11-07T19:11:59.481939Z","shell.execute_reply":"2023-11-07T19:11:59.481025Z","shell.execute_reply.started":"2023-11-07T19:11:59.470977Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Columns removed\n"]}],"source":["# removing passengerId, cabin, column \n","passengerId = test_data['PassengerId']\n","train_dataset = train_dataset.drop(columns=['Cabin', 'PassengerId'])\n","val_dataset = val_dataset.drop(columns=['Cabin', 'PassengerId'])\n","test_data = test_data.drop(columns=['Cabin', 'PassengerId'])\n","print('Columns removed')"]},{"cell_type":"markdown","metadata":{},"source":["### Handle Missing Values"]},{"cell_type":"markdown","metadata":{},"source":["#### Training dataset"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:02.755436Z","iopub.status.busy":"2023-11-07T19:12:02.754968Z","iopub.status.idle":"2023-11-07T19:12:02.767853Z","shell.execute_reply":"2023-11-07T19:12:02.766528Z","shell.execute_reply.started":"2023-11-07T19:12:02.755398Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["training dataset missing values handled\n"]}],"source":["# handle Age column missing values\n","train_ages = train_dataset['Age']\n","train_non_nan_ages = train_ages[~np.isnan(train_ages)]\n","train_ages_mean = train_non_nan_ages.mean()\n","train_dataset['Age'] = train_dataset['Age'].fillna(train_ages_mean)\n","# handle Embarked\n","train_embarked = train_dataset['Embarked']\n","train_embarked_mode = train_embarked.mode()\n","train_dataset['Embarked'].replace(' ', np.nan, inplace=True) # Replacing non-visible missing values with NaN\n","train_dataset['Embarked'] = train_dataset['Embarked'].fillna('S')\n","print('training dataset missing values handled')"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:05.460526Z","iopub.status.busy":"2023-11-07T19:12:05.460090Z","iopub.status.idle":"2023-11-07T19:12:05.474868Z","shell.execute_reply":"2023-11-07T19:12:05.473914Z","shell.execute_reply.started":"2023-11-07T19:12:05.460493Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 623 entries, 445 to 102\n","Data columns (total 9 columns):\n"," #   Column    Non-Null Count  Dtype  \n","---  ------    --------------  -----  \n"," 0   Pclass    623 non-null    int64  \n"," 1   Name      623 non-null    object \n"," 2   Sex       623 non-null    object \n"," 3   Age       623 non-null    float64\n"," 4   SibSp     623 non-null    int64  \n"," 5   Parch     623 non-null    int64  \n"," 6   Ticket    623 non-null    object \n"," 7   Fare      623 non-null    float64\n"," 8   Embarked  623 non-null    object \n","dtypes: float64(2), int64(3), object(4)\n","memory usage: 48.7+ KB\n"]}],"source":["train_dataset.info()"]},{"cell_type":"markdown","metadata":{},"source":["#### Val dataset"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:08.179402Z","iopub.status.busy":"2023-11-07T19:12:08.178705Z","iopub.status.idle":"2023-11-07T19:12:08.202494Z","shell.execute_reply":"2023-11-07T19:12:08.201193Z","shell.execute_reply.started":"2023-11-07T19:12:08.179353Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["val dataset missing values handled\n"]}],"source":["# handle Age column missing values\n","val_ages = val_dataset['Age']\n","val_non_nan_ages = val_ages[~np.isnan(val_ages)]\n","val_ages_mean = val_non_nan_ages.mean() # handling missing values with the mean of the ages\n","val_dataset['Age'] = val_dataset['Age'].fillna(val_ages_mean)\n","# handle Embarked\n","val_embarked = val_dataset['Embarked']\n","val_embarked_mode = val_dataset.mode()\n","val_dataset['Embarked'].replace(' ', np.nan, inplace=True) # Replacing non-visible missing values with NaN\n","val_dataset['Embarked'] = val_dataset['Embarked'].fillna('S')\n","print('val dataset missing values handled')"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:10.537274Z","iopub.status.busy":"2023-11-07T19:12:10.536851Z","iopub.status.idle":"2023-11-07T19:12:10.551648Z","shell.execute_reply":"2023-11-07T19:12:10.550348Z","shell.execute_reply.started":"2023-11-07T19:12:10.537242Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 268 entries, 709 to 430\n","Data columns (total 9 columns):\n"," #   Column    Non-Null Count  Dtype  \n","---  ------    --------------  -----  \n"," 0   Pclass    268 non-null    int64  \n"," 1   Name      268 non-null    object \n"," 2   Sex       268 non-null    object \n"," 3   Age       268 non-null    float64\n"," 4   SibSp     268 non-null    int64  \n"," 5   Parch     268 non-null    int64  \n"," 6   Ticket    268 non-null    object \n"," 7   Fare      268 non-null    float64\n"," 8   Embarked  268 non-null    object \n","dtypes: float64(2), int64(3), object(4)\n","memory usage: 20.9+ KB\n"]}],"source":["val_dataset.info()"]},{"cell_type":"markdown","metadata":{},"source":["#### Test data"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:12.476842Z","iopub.status.busy":"2023-11-07T19:12:12.476426Z","iopub.status.idle":"2023-11-07T19:12:12.489605Z","shell.execute_reply":"2023-11-07T19:12:12.488174Z","shell.execute_reply.started":"2023-11-07T19:12:12.476810Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["test data missing values handled\n"]}],"source":["# handle Age column missing values\n","test_ages = test_data['Age']\n","test_non_nan_ages = test_ages[~np.isnan(test_ages)]\n","test_ages_mean = test_non_nan_ages.mean()\n","test_data['Age'] = test_data['Age'].fillna(test_ages_mean)\n","# handle Embarked\n","test_data['Embarked'].replace(' ', np.nan, inplace=True) # Replacing non-visible missing values with NaN\n","test_data['Embarked'] = test_data['Embarked'].fillna('S') # imputing 'S' from mode \n","# handle Fare\n","test_data['Fare'].replace(' ', np.nan, inplace=True)\n","test_data['Fare'] = test_data['Fare'].fillna(7.75) # 7.75 from mode\n","print('test data missing values handled')"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:14.816771Z","iopub.status.busy":"2023-11-07T19:12:14.815637Z","iopub.status.idle":"2023-11-07T19:12:14.831055Z","shell.execute_reply":"2023-11-07T19:12:14.829728Z","shell.execute_reply.started":"2023-11-07T19:12:14.816735Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 418 entries, 0 to 417\n","Data columns (total 9 columns):\n"," #   Column    Non-Null Count  Dtype  \n","---  ------    --------------  -----  \n"," 0   Pclass    418 non-null    int64  \n"," 1   Name      418 non-null    object \n"," 2   Sex       418 non-null    object \n"," 3   Age       418 non-null    float64\n"," 4   SibSp     418 non-null    int64  \n"," 5   Parch     418 non-null    int64  \n"," 6   Ticket    418 non-null    object \n"," 7   Fare      418 non-null    float64\n"," 8   Embarked  418 non-null    object \n","dtypes: float64(2), int64(3), object(4)\n","memory usage: 29.5+ KB\n"]}],"source":["test_data.info()"]},{"cell_type":"markdown","metadata":{},"source":["### Handle Categorical values (encoding)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:16.631689Z","iopub.status.busy":"2023-11-07T19:12:16.631271Z","iopub.status.idle":"2023-11-07T19:12:16.711161Z","shell.execute_reply":"2023-11-07T19:12:16.709907Z","shell.execute_reply.started":"2023-11-07T19:12:16.631654Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["processing the following cat cols: ['Name', 'Sex', 'Ticket', 'Embarked']\n","(623, 1128)\n","(268, 1128)\n","(418, 1128)\n","categorical data handled\n"]}],"source":["# init the encoder\n","encoder = OneHotEncoder(handle_unknown='ignore')\n","# encoder = TargetEncoder()\n","\n","# get categorical columns\n","cat_cols = [cname for cname in train_dataset.columns if \n","           train_dataset[cname].dtype == \"object\"]\n","\n","print('processing the following cat cols: ' + str(cat_cols))\n","\n","# fit the encoder in the training data and then use it on the other datasets\n","train_data_encoded = encoder.fit_transform(train_dataset[cat_cols])\n","val_data_encoded = encoder.transform(val_dataset[cat_cols])\n","test_data_encoded = encoder.transform(test_data[cat_cols])\n","\n","# convert encoded datasets to pandas dataframes \n","train_data_encoded_df = pd.DataFrame(train_data_encoded.toarray(), columns=encoder.get_feature_names_out(cat_cols))\n","val_data_encoded_df = pd.DataFrame(val_data_encoded.toarray(), columns=encoder.get_feature_names_out(cat_cols))\n","test_data_encoded_df = pd.DataFrame(test_data_encoded.toarray(), columns=encoder.get_feature_names_out(cat_cols))\n","\n","# drop cat cols from original dataset\n","train_dataset = train_dataset.drop(columns=cat_cols, axis=1)\n","val_dataset = val_dataset.drop(columns=cat_cols, axis=1)\n","test_data = test_data.drop(columns=cat_cols, axis=1)\n","\n","# Concatenate with the rest of the features (here we do .reset_index(drop=True) to reset the prevs persisted indexes)\n","train_dataset_encoded = pd.concat([train_dataset.reset_index(drop=True), train_data_encoded_df], axis=1)\n","val_dataset_encoded = pd.concat([val_dataset.reset_index(drop=True), val_data_encoded_df], axis=1)\n","test_dataset_encoded = pd.concat([test_data.reset_index(drop=True), test_data_encoded_df], axis=1)\n","\n","print(train_dataset_encoded.shape)\n","print(val_dataset_encoded.shape)\n","print(test_dataset_encoded.shape)\n","\n","print('categorical data handled')"]},{"cell_type":"markdown","metadata":{},"source":["### Normalization"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:21.452902Z","iopub.status.busy":"2023-11-07T19:12:21.452403Z","iopub.status.idle":"2023-11-07T19:12:21.552013Z","shell.execute_reply":"2023-11-07T19:12:21.550765Z","shell.execute_reply.started":"2023-11-07T19:12:21.452859Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(623, 1128)\n","(268, 1128)\n","(418, 1128)\n","data normalized\n"]}],"source":["# initialized the scaler \n","scaler = MinMaxScaler()\n","\n","# normalize train data\n","train_data_scaled = scaler.fit_transform(train_dataset_encoded)\n","val_data_scaled = scaler.transform(val_dataset_encoded)\n","test_data_scaled = scaler.transform(test_dataset_encoded)\n","\n","print(train_data_scaled.shape)\n","print(val_data_scaled.shape)\n","print(test_data_scaled.shape)\n","\n","# Verify that data has been normalized correctly\n","print(np.max(train_data_scaled))\n","print(np.min(train_data_scaled))\n","\n","print('data normalized')"]},{"cell_type":"markdown","metadata":{},"source":["## Build the models"]},{"cell_type":"markdown","metadata":{},"source":["### Models Implementation"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:29.952167Z","iopub.status.busy":"2023-11-07T19:12:29.951711Z","iopub.status.idle":"2023-11-07T19:12:31.405351Z","shell.execute_reply":"2023-11-07T19:12:31.404142Z","shell.execute_reply.started":"2023-11-07T19:12:29.952126Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["models set\n"]}],"source":["# logistic regression model\n","logistic_regression_model = LogisticRegression()\n","logistic_regression_model.fit(train_data_scaled, train_labels)\n","\n","# random forest model\n","random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","random_forest_model.fit(train_data_scaled, train_labels)\n","\n","# support vector classifier model\n","svm_model = SVC(kernel=\"linear\")\n","svm_model.fit(train_data_scaled, train_labels)\n","\n","# naive bayes multinomial classifier\n","nb_model = MultinomialNB()\n","nb_model.fit(train_data_scaled, train_labels)\n","\n","# k-nearest neighbors classifier\n","knn_model = KNeighborsClassifier(n_neighbors=5)\n","knn_model.fit(train_data_scaled, train_labels)\n","\n","# Adaboost classifier\n","adaboost_base_classifier = DecisionTreeClassifier(max_depth=1)\n","adaboost_model = AdaBoostClassifier(adaboost_base_classifier, n_estimators=50, random_state=42)\n","adaboost_model.fit(train_data_scaled, train_labels)\n","\n","print('models set')"]},{"cell_type":"markdown","metadata":{},"source":["## Make Predictions"]},{"cell_type":"markdown","metadata":{},"source":["### Generate predictions for Logistic Regression Model"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:35.491390Z","iopub.status.busy":"2023-11-07T19:12:35.490752Z","iopub.status.idle":"2023-11-07T19:12:35.499193Z","shell.execute_reply":"2023-11-07T19:12:35.497646Z","shell.execute_reply.started":"2023-11-07T19:12:35.491351Z"},"trusted":true},"outputs":[],"source":["def model_metrics(train_pred):\n","    accuracy = accuracy_score(val_labels, train_pred)\n","    confusion = confusion_matrix(val_labels, train_pred)\n","    report = classification_report(val_labels, train_pred)\n","\n","    print(\"Accuracy:\", accuracy)\n","    print(\"Confusion Matrix:\\n\", confusion)\n","    print(\"Classification Report:\\n\", report)\n","    \n","    return accuracy"]},{"cell_type":"markdown","metadata":{},"source":["#### train predictions "]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:04:56.541688Z","iopub.status.busy":"2023-11-07T19:04:56.541246Z","iopub.status.idle":"2023-11-07T19:04:56.579919Z","shell.execute_reply":"2023-11-07T19:04:56.578172Z","shell.execute_reply.started":"2023-11-07T19:04:56.541652Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.8097014925373134\n","Confusion Matrix:\n"," [[137  20]\n"," [ 31  80]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.82      0.87      0.84       157\n","           1       0.80      0.72      0.76       111\n","\n","    accuracy                           0.81       268\n","   macro avg       0.81      0.80      0.80       268\n","weighted avg       0.81      0.81      0.81       268\n","\n","train preds made for regression model\n","Accuracy: 0.8208955223880597\n","Confusion Matrix:\n"," [[147  10]\n"," [ 38  73]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.79      0.94      0.86       157\n","           1       0.88      0.66      0.75       111\n","\n","    accuracy                           0.82       268\n","   macro avg       0.84      0.80      0.81       268\n","weighted avg       0.83      0.82      0.82       268\n","\n","train preds made for random forest model\n","Accuracy: 0.8171641791044776\n","Confusion Matrix:\n"," [[141  16]\n"," [ 33  78]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.81      0.90      0.85       157\n","           1       0.83      0.70      0.76       111\n","\n","    accuracy                           0.82       268\n","   macro avg       0.82      0.80      0.81       268\n","weighted avg       0.82      0.82      0.81       268\n","\n","train preds made for svm model\n","Accuracy: 0.746268656716418\n","Confusion Matrix:\n"," [[153   4]\n"," [ 64  47]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.71      0.97      0.82       157\n","           1       0.92      0.42      0.58       111\n","\n","    accuracy                           0.75       268\n","   macro avg       0.81      0.70      0.70       268\n","weighted avg       0.79      0.75      0.72       268\n","\n","train preds made for nb model\n","Accuracy: 0.7985074626865671\n","Confusion Matrix:\n"," [[140  17]\n"," [ 37  74]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.79      0.89      0.84       157\n","           1       0.81      0.67      0.73       111\n","\n","    accuracy                           0.80       268\n","   macro avg       0.80      0.78      0.79       268\n","weighted avg       0.80      0.80      0.79       268\n","\n","train preds for knn model\n","Accuracy: 0.8059701492537313\n","Confusion Matrix:\n"," [[134  23]\n"," [ 29  82]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.82      0.85      0.84       157\n","           1       0.78      0.74      0.76       111\n","\n","    accuracy                           0.81       268\n","   macro avg       0.80      0.80      0.80       268\n","weighted avg       0.81      0.81      0.81       268\n","\n","train preds for adaboost model\n"]}],"source":["val_preds_regression_model = logistic_regression_model.predict(val_data_scaled)\n","regression_model_accuracy = model_metrics(val_preds_regression_model)\n","print('train preds made for regression model')\n","\n","val_preds_random_forest_model = random_forest_model.predict(val_data_scaled)\n","random_forest_model_accuracy = model_metrics(val_preds_random_forest_model)\n","print('train preds made for random forest model')\n","\n","val_preds_svm_model = svm_model.predict(val_data_scaled)\n","svm_model_accuracy = model_metrics(val_preds_svm_model)\n","print('train preds made for svm model')\n","\n","val_preds_nb_model = nb_model.predict(val_data_scaled)\n","nb_model_accuracy = model_metrics(val_preds_nb_model)\n","print('train preds made for nb model')\n","\n","val_preds_knn_model = knn_model.predict(val_data_scaled)\n","knn_model_accuracy = model_metrics(val_preds_knn_model)\n","print('train preds for knn model')\n","\n","val_preds_adaboost_model = adaboost_model.predict(val_data_scaled)\n","adaboost_model_accuracy = model_metrics(val_preds_adaboost_model)\n","print('train preds for adaboost model')"]},{"cell_type":"markdown","metadata":{},"source":["### Submission"]},{"cell_type":"markdown","metadata":{},"source":["#### Real predictions"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:45.797954Z","iopub.status.busy":"2023-11-07T19:12:45.797529Z","iopub.status.idle":"2023-11-07T19:12:45.851769Z","shell.execute_reply":"2023-11-07T19:12:45.850538Z","shell.execute_reply.started":"2023-11-07T19:12:45.797919Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train preds made\n"]}],"source":["preds = nb_model.predict(test_data_scaled)\n","print('train preds made')"]},{"cell_type":"markdown","metadata":{},"source":["#### Generate submission"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:48.223300Z","iopub.status.busy":"2023-11-07T19:12:48.222833Z","iopub.status.idle":"2023-11-07T19:12:48.230897Z","shell.execute_reply":"2023-11-07T19:12:48.229616Z","shell.execute_reply.started":"2023-11-07T19:12:48.223265Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["submission set\n"]}],"source":["# generate data frame for submision\n","submission = pd.DataFrame({\n","    \"PassengerId\": passengerId,\n","    \"Survived\": preds\n","})\n","\n","print('submission set')"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:50.704347Z","iopub.status.busy":"2023-11-07T19:12:50.703923Z","iopub.status.idle":"2023-11-07T19:12:50.716614Z","shell.execute_reply":"2023-11-07T19:12:50.715508Z","shell.execute_reply.started":"2023-11-07T19:12:50.704312Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>892</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>893</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>894</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>895</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>896</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>897</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>898</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>899</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>900</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>901</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>902</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>903</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>904</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>905</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>906</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>907</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>908</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>909</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>910</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>911</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    PassengerId  Survived\n","0           892         0\n","1           893         0\n","2           894         0\n","3           895         0\n","4           896         1\n","5           897         0\n","6           898         1\n","7           899         0\n","8           900         1\n","9           901         0\n","10          902         0\n","11          903         0\n","12          904         1\n","13          905         0\n","14          906         0\n","15          907         1\n","16          908         0\n","17          909         0\n","18          910         0\n","19          911         1"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["submission.head(20)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-11-07T19:12:53.585923Z","iopub.status.busy":"2023-11-07T19:12:53.585522Z","iopub.status.idle":"2023-11-07T19:12:53.595566Z","shell.execute_reply":"2023-11-07T19:12:53.594069Z","shell.execute_reply.started":"2023-11-07T19:12:53.585892Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["submission file generated\n"]}],"source":["# write the file to submission\n","submission.to_csv('./submissions/titanic_dissaster_submission_nb_first_attempt.csv', index=False, header=True)\n","print('submission file generated')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":4}
